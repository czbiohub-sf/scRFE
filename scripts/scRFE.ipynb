{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scRFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MENTION ONE VS ALL CLASSIFICATION in description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import random\n",
    "from anndata import read_h5ad\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterNormalize (dataMatrix, classOfInterest):\n",
    "    np.random.seed(644685)\n",
    "    sc.logging.print_versions()\n",
    "    sc.settings.verbosity = 3      \n",
    "    sc.logging.print_versions()\n",
    "    tiss = dataMatrix\n",
    "    tiss.obs['n_counts'] = tiss.X.sum(axis=1).A1\n",
    "    sc.pp.filter_cells(tiss, min_genes=250)\n",
    "    sc.pp.filter_genes(tiss, min_cells=3)\n",
    "    tiss = tiss[tiss.obs['n_counts'] > 1500, :]\n",
    "    sc.pp.normalize_per_cell(tiss, counts_per_cell_after=1e5)\n",
    "    sc.pp.log1p(tiss)\n",
    "    tiss.raw = tiss\n",
    "    tiss = tiss[tiss.obs[classOfInterest]!='nan']\n",
    "    return tiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal: get labels on a per class basis that will go into randomForest function for y\n",
    "def getLabels (dataMatrix, classOfInterest): \n",
    "    \"\"\"\n",
    "    Gets labels on a per class basis that will inputted to the randomForest function\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataMatrix : anndata object\n",
    "        The data file of interest\n",
    "    classOfInterest : str\n",
    "        The class you will split the data by in the set of dataMatrix.obs\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    labelsDict : dict\n",
    "        Dictionary with labels for each class \n",
    "    \"\"\"\n",
    "    dataMatrix = filterNormalize (dataMatrix, classOfInterest)\n",
    "    labelsDict = {}\n",
    "    for label in np.unique(dataMatrix.obs[classOfInterest]):\n",
    "        lists = []        \n",
    "        for obs in dataMatrix.obs[classOfInterest]:\n",
    "            if obs == label: \n",
    "                lists.append('A')\n",
    "            else:\n",
    "                lists.append('B')\n",
    "        labelsDict[label] = lists #this is usually in line w if and else    \n",
    "    return labelsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeOneForest (dataMatrix, classOfInterest, labelOfInterest, nEstimators = 5000, \n",
    "                   randomState = 0,  nJobs = -1, oobScore = True, Step = 0.2, Cv = 5): \n",
    "    \"\"\"\n",
    "    Builds and runs a random forest for one label in a class of interest\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataMatrix : anndata object\n",
    "        The data file of interest\n",
    "    classOfInterest : str\n",
    "        The class you will split the data by in the set of dataMatrix.obs\n",
    "    labelOfInterest : str\n",
    "        The specific label within the class that the random forezt will run a \n",
    "        \"one vs all\" classification on\n",
    "    nEstimators : int\n",
    "        The number of trees in the forest\n",
    "    randomState : int\n",
    "        Controls random number being used\n",
    "    nJobs : int\n",
    "        The number of jobs to run in parallel\n",
    "    oobScore : bool\n",
    "        Whether to use out-of-bag samples to estimate the generalization accuracy\n",
    "    Step : float\n",
    "        Corresponds to percentage of features to remove at each iteration\n",
    "    Cv : int\n",
    "        Determines the cross-validation splitting strategy\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    feature_selected : list\n",
    "        list of top features from random forest\n",
    "    selector.estimator_.feature_importances_ : list\n",
    "        list of top ginis corresponding to to features\n",
    "    \n",
    "    \"\"\"\n",
    "    dataMatrix = filterNormalize (dataMatrix, classOfInterest)\n",
    "\n",
    "    print('makeOneForest' + labelOfInterest)\n",
    "    labelsDict = getLabels(dataMatrix, classOfInterest) \n",
    "\n",
    "    feat_labels = dataMatrix.var_names #this is equivalent of the genes\n",
    "    X = dataMatrix.X\n",
    "    y = labelsDict[labelOfInterest]\n",
    "    print('Y')\n",
    "    print(len(y))\n",
    "    clf = RandomForestClassifier(n_estimators = nEstimators, random_state = randomState, \n",
    "                                 n_jobs = nJobs, oob_score = oobScore)\n",
    "    selector = RFECV(clf, step = Step, cv = Cv)\n",
    "    \n",
    "    print('training...')\n",
    "    clf.fit(X, y)\n",
    "    selector.fit(X, y)\n",
    "    feature_selected = feat_labels[selector.support_] \n",
    "\n",
    "    return feature_selected, selector.estimator_.feature_importances_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultWrite (classOfInterest, results_df, labelOfInterest,\n",
    "                feature_selected, feature_importance):\n",
    "    print ('result writing')\n",
    "    print(results_df)\n",
    "    \n",
    "    column_headings = [] \n",
    "    column_headings.append(labelOfInterest)\n",
    "    column_headings.append(labelOfInterest + '_gini')\n",
    "    resaux = pd.DataFrame(columns = column_headings)\n",
    "    resaux[labelOfInterest] = feature_selected\n",
    "    resaux[labelOfInterest + '_gini'] = feature_importance\n",
    "    resaux = resaux.sort_values(by = [labelOfInterest + '_gini'], ascending = False)\n",
    "    resaux.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    results_df = pd.concat([results_df, resaux], axis=1)\n",
    "    return results_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scRFE(dataMatrix, classOfInterest, nEstimators = 5000, randomState = 0,  \n",
    "                  nJobs = -1, oobScore = True, Step = 0.2, Cv = 5):\n",
    "    \"\"\"\n",
    "    Builds and runs a random forest with one vs all classification for each label \n",
    "    for one class of interest\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataMatrix : anndata object\n",
    "        The data file of interest\n",
    "    classOfInterest : str\n",
    "        The class you will split the data by in the set of dataMatrix.obs\n",
    "    labelOfInterest : str\n",
    "        The specific label within the class that the random forezt will run a \n",
    "        \"one vs all\" classification on\n",
    "    nEstimators : int\n",
    "        The number of trees in the forest\n",
    "    randomState : int\n",
    "        Controls random number being used\n",
    "    nJobs : int\n",
    "        The number of jobs to run in parallel\n",
    "    oobScore : bool\n",
    "        Whether to use out-of-bag samples to estimate the generalization accuracy\n",
    "    Step : float\n",
    "        Corresponds to percentage of features to remove at each iteration\n",
    "    Cv : int\n",
    "        Determines the cross-validation splitting strategy\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pd.DataFrame\n",
    "        Dataframe with results for each label in the class, formatted as \n",
    "        \"label\" for one column, then \"label + gini\" for the corresponding column\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    dataMatrix = filterNormalize (dataMatrix, classOfInterest)\n",
    "    results_df = pd.DataFrame()\n",
    "    for labelOfInterest in np.unique(dataMatrix.obs[classOfInterest]): #for timeliness    \n",
    "        print( 'scRFE' + labelOfInterest)\n",
    "        \n",
    "        feature_selected, feature_importance = makeOneForest(dataMatrix, \n",
    "                                                             classOfInterest, \n",
    "                          labelOfInterest = labelOfInterest)\n",
    "    \n",
    "        results_df = resultWrite (classOfInterest, results_df, \n",
    "                            labelOfInterest = labelOfInterest, \n",
    "                    feature_selected = feature_selected,  \n",
    "                    feature_importance = feature_importance)\n",
    "        print(results_df.shape)\n",
    "    return results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
