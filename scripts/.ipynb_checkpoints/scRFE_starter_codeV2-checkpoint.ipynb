{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scRFE Starter CodeV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2020-05-01\n",
    "# getLabels Function, adding makeOneClassForest Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from anndata import read_h5ad\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "adata = read_h5ad('/Users/madelinepark/Downloads/Kidney_facs.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal: get labels on a per class basis that will go into randomForest function for y\n",
    "def getLabels3(dataMatrix, classOfInterest): \n",
    "    labelsDict = {}\n",
    "    for label in np.unique(adata.obs[classOfInterest]):\n",
    "        lists = []\n",
    "        for obs in adata.obs[classOfInterest]:\n",
    "            if obs == label: \n",
    "                lists.append('1')\n",
    "            else:\n",
    "                lists.append('0')\n",
    "            labelsDict[obs] = pd.Series(lists) \n",
    "#         print(len(pd.Series(lists)))\n",
    "    return labelsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsDict = getLabels3(dataMatrix = adata, classOfInterest = 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal: get labels on a per class basis that will go into randomForest function for y\n",
    "def getLabels (dataMatrix, classOfInterest): \n",
    "    labelsDict = {}\n",
    "    for label in np.unique(adata.obs[classOfInterest]):\n",
    "        lists = []\n",
    "        for obs in adata.obs[classOfInterest]:\n",
    "            if obs == label: \n",
    "                lists.append('1')\n",
    "            else:\n",
    "                lists.append('0')\n",
    "            labelsDict[obs] = lists\n",
    "    return labelsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# call getLabels2\n",
    "labelsDict = getLabels(dataMatrix = adata, classOfInterest = 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsDict\n",
    "labelsDict['24m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal: make a random forest where X is adata.X and y is the labels from labelsDict\n",
    "def makeOneClassForest(dataMatrix, classOfInterest, step=0.2, cv=3,  n_estimators=1000, random_state=0, n_jobs=-1, oob_score=True):\n",
    "    results_df = pd.DataFrame() \n",
    "    labelsDict = getLabels(dataMatrix = adata, classOfInterest = 'age') #is it bad to hardcode this\n",
    "    for label in list(labelsDict.keys()):\n",
    "        print(label)\n",
    "        \n",
    "        y = labelsDict[label] #list of strings \n",
    "        clf = RandomForestClassifier(n_estimators, random_state, n_jobs, oob_score)\n",
    "        selector = RFECV(clf, step, cv) # step = % rounded down at each iteration\n",
    "        \n",
    "        print(type(y))\n",
    "        print((y))\n",
    "\n",
    "        print(type(tiss.obs['age_type_of_interest']))\n",
    "        \n",
    "        clf.fit(dataMatrix.X, y) #confused if this y is labels or the genes because feat_labels is genes\n",
    "        selector.fit(dataMatrix.X, y)\n",
    "        feature_selected = dataMatrix.var_names[selector.support_] #check dataMatrix.var_names\n",
    "#         feat_labels = tiss.var_names #this is all the genes, apparently called an index \n",
    "    #     X = tiss.X #scipy sparse matrix \n",
    "    #     y = tiss.obs['age_type_of_interest'] #series \n",
    "    #     clf.fit(X_train, y_train)\n",
    "    #     selector.fit(X_train, y_train)\n",
    "    #     feature_selected = feat_labels[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeOneClassForest(dataMatrix = adata, classOfInterest = 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24m\n",
      "training...\n",
      "index\n",
      "M14_B001261_S278_L003.mus-2-0     24m\n",
      "N3.MAA000545.3_8_M.1.1-1         rest\n",
      "K16.MAA000752.3_10_M.1.1-1       rest\n",
      "C22.MAA000922.3_9_M.1.1-1        rest\n",
      "L12.B001717.3_38_F.1.1-1         rest\n",
      "E13.B001717.3_38_F.1.1-1         rest\n",
      "I6.B001717.3_38_F.1.1-1          rest\n",
      "E20_B000846_S116_L003.mus-6-0     24m\n",
      "L8_B001261_S248_L003.mus-2-0      24m\n",
      "A18_B001261_S294_L003.mus-2-0     24m\n",
      "K6_B000846_S246_L003.mus-6-0      24m\n",
      "L7.MAA000801.3_11_M.1.1-1        rest\n",
      "G17_B001261_S137_L003.mus-2-0     24m\n",
      "B2_B000846_S26_L003.mus-6-0       24m\n",
      "D20_B001261_S68_L003.mus-2-0      24m\n",
      "M14.MAA000752.3_10_M.1.1-1       rest\n",
      "E16_B001261_S88_L003.mus-2-0      24m\n",
      "L10_B000846_S274_L003.mus-6-0     24m\n",
      "A19_B000846_S19_L003.mus-6-0      24m\n",
      "G9.B002775.3_39_F.1.1-1          rest\n",
      "O20.MAA000545.3_8_M.1.1-1        rest\n",
      "O16.MAA000752.3_10_M.1.1-1       rest\n",
      "N13.MAA000545.3_8_M.1.1-1        rest\n",
      "A9_B001259_S237_L004.mus-4-0      24m\n",
      "P10.MAA000801.3_11_M.1.1-1       rest\n",
      "E12_B001261_S84_L003.mus-2-0      24m\n",
      "B18_B000844_S294_L001.mus-5-0     24m\n",
      "B2.MAA000545.3_8_M.1.1-1         rest\n",
      "F2.B001717.3_38_F.1.1-1          rest\n",
      "B20.B001717.3_38_F.1.1-1         rest\n",
      "                                 ... \n",
      "N15_B000846_S327_L003.mus-6-0     24m\n",
      "P16.MAA000801.3_11_M.1.1-1       rest\n",
      "L22.MAA000752.3_10_M.1.1-1       rest\n",
      "H2_B001261_S146_L003.mus-2-0      24m\n",
      "A14.B002775.3_39_F.1.1-1         rest\n",
      "G4_B000844_S100_L001.mus-5-0      24m\n",
      "K4_B000846_S244_L003.mus-6-0      24m\n",
      "D22.MAA000801.3_11_M.1.1-1       rest\n",
      "J11_B001261_S203_L003.mus-2-0     24m\n",
      "L6_B000846_S270_L003.mus-6-0      24m\n",
      "F19_B001261_S115_L003.mus-2-0     24m\n",
      "A12.MAA000801.3_11_M.1.1-1       rest\n",
      "L8_B000844_S224_L001.mus-5-0      24m\n",
      "A14.B001717.3_38_F.1.1-1         rest\n",
      "N2_B001261_S290_L003.mus-2-0      24m\n",
      "G20_B001261_S140_L003.mus-2-0     24m\n",
      "M2_B000844_S242_L001.mus-5-0      24m\n",
      "I10_B000846_S202_L003.mus-6-0     24m\n",
      "K3_B001259_S171_L004.mus-4-0      24m\n",
      "P7_B000844_S19_L001.mus-5-0       24m\n",
      "I13.MAA000752.3_10_M.1.1-1       rest\n",
      "P6_B000844_S18_L001.mus-5-0       24m\n",
      "G6_B001259_S78_L004.mus-4-0       24m\n",
      "F3.MAA000922.3_9_M.1.1-1         rest\n",
      "P20.B001717.3_38_F.1.1-1         rest\n",
      "L14_B000846_S278_L003.mus-6-0     24m\n",
      "P5_B000846_S365_L003.mus-6-0      24m\n",
      "L8.MAA000545.3_8_M.1.1-1         rest\n",
      "N18_B000844_S282_L001.mus-5-0     24m\n",
      "F7_B000846_S127_L003.mus-6-0      24m\n",
      "Name: age_type_of_interest, Length: 1330, dtype: object\n",
      "3m\n",
      "training...\n",
      "index\n",
      "M14_B001261_S278_L003.mus-2-0    rest\n",
      "N3.MAA000545.3_8_M.1.1-1           3m\n",
      "K16.MAA000752.3_10_M.1.1-1         3m\n",
      "C22.MAA000922.3_9_M.1.1-1          3m\n",
      "L12.B001717.3_38_F.1.1-1           3m\n",
      "E13.B001717.3_38_F.1.1-1           3m\n",
      "I6.B001717.3_38_F.1.1-1            3m\n",
      "E20_B000846_S116_L003.mus-6-0    rest\n",
      "L8_B001261_S248_L003.mus-2-0     rest\n",
      "A18_B001261_S294_L003.mus-2-0    rest\n",
      "K6_B000846_S246_L003.mus-6-0     rest\n",
      "L7.MAA000801.3_11_M.1.1-1          3m\n",
      "G17_B001261_S137_L003.mus-2-0    rest\n",
      "B2_B000846_S26_L003.mus-6-0      rest\n",
      "D20_B001261_S68_L003.mus-2-0     rest\n",
      "M14.MAA000752.3_10_M.1.1-1         3m\n",
      "E16_B001261_S88_L003.mus-2-0     rest\n",
      "L10_B000846_S274_L003.mus-6-0    rest\n",
      "A19_B000846_S19_L003.mus-6-0     rest\n",
      "G9.B002775.3_39_F.1.1-1            3m\n",
      "O20.MAA000545.3_8_M.1.1-1          3m\n",
      "O16.MAA000752.3_10_M.1.1-1         3m\n",
      "N13.MAA000545.3_8_M.1.1-1          3m\n",
      "A9_B001259_S237_L004.mus-4-0     rest\n",
      "P10.MAA000801.3_11_M.1.1-1         3m\n",
      "E12_B001261_S84_L003.mus-2-0     rest\n",
      "B18_B000844_S294_L001.mus-5-0    rest\n",
      "B2.MAA000545.3_8_M.1.1-1           3m\n",
      "F2.B001717.3_38_F.1.1-1            3m\n",
      "B20.B001717.3_38_F.1.1-1           3m\n",
      "                                 ... \n",
      "N15_B000846_S327_L003.mus-6-0    rest\n",
      "P16.MAA000801.3_11_M.1.1-1         3m\n",
      "L22.MAA000752.3_10_M.1.1-1         3m\n",
      "H2_B001261_S146_L003.mus-2-0     rest\n",
      "A14.B002775.3_39_F.1.1-1           3m\n",
      "G4_B000844_S100_L001.mus-5-0     rest\n",
      "K4_B000846_S244_L003.mus-6-0     rest\n",
      "D22.MAA000801.3_11_M.1.1-1         3m\n",
      "J11_B001261_S203_L003.mus-2-0    rest\n",
      "L6_B000846_S270_L003.mus-6-0     rest\n",
      "F19_B001261_S115_L003.mus-2-0    rest\n",
      "A12.MAA000801.3_11_M.1.1-1         3m\n",
      "L8_B000844_S224_L001.mus-5-0     rest\n",
      "A14.B001717.3_38_F.1.1-1           3m\n",
      "N2_B001261_S290_L003.mus-2-0     rest\n",
      "G20_B001261_S140_L003.mus-2-0    rest\n",
      "M2_B000844_S242_L001.mus-5-0     rest\n",
      "I10_B000846_S202_L003.mus-6-0    rest\n",
      "K3_B001259_S171_L004.mus-4-0     rest\n",
      "P7_B000844_S19_L001.mus-5-0      rest\n",
      "I13.MAA000752.3_10_M.1.1-1         3m\n",
      "P6_B000844_S18_L001.mus-5-0      rest\n",
      "G6_B001259_S78_L004.mus-4-0      rest\n",
      "F3.MAA000922.3_9_M.1.1-1           3m\n",
      "P20.B001717.3_38_F.1.1-1           3m\n",
      "L14_B000846_S278_L003.mus-6-0    rest\n",
      "P5_B000846_S365_L003.mus-6-0     rest\n",
      "L8.MAA000545.3_8_M.1.1-1           3m\n",
      "N18_B000844_S282_L001.mus-5-0    rest\n",
      "F7_B000846_S127_L003.mus-6-0     rest\n",
      "Name: age_type_of_interest, Length: 1330, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# JUST TESTING\n",
    "for c in list(set(tiss.obs['age'])): \n",
    "    print(c)\n",
    "    age_of_interest = c\n",
    "    tiss.obs['age_type_of_interest'] = 'rest' #moved into, was outside before\n",
    "    tiss.obs.loc[tiss.obs['age'] == age_of_interest,'age_type_of_interest'] = age_of_interest\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=10, random_state=0, n_jobs=-1, oob_score=True)\n",
    "    selector = RFECV(clf, step=0.2, cv=3, n_jobs=4) # step = % rounded down at each iteration  \n",
    "    \n",
    "# #     tiss.obs.loc[tiss.obs[tiss.obs['age'] == age_of_interest].index,'age_type_of_interest'] = age_of_interest\n",
    "#     tiss.obs.loc[tiss.obs['age'] == age_of_interest,'age_type_of_interest'] = age_of_interest\n",
    "\n",
    "    feat_labels = tiss.var_names \n",
    "    X = tiss.X\n",
    "    y = tiss.obs['age_type_of_interest']\n",
    "    \n",
    "    print('training...')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0) \n",
    "    print((y_train))\n",
    "# clf.fit(X_train, y_train)\n",
    "#     selector.fit(X_train, y_train)\n",
    "#     feature_selected = feat_labels[selector.support_] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudocode/brainstorm for random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 3-4\n",
    "# X, y = make_classification(n_samples=1000, n_features=4,\n",
    "#                            n_informative=2, n_redundant=0,\n",
    "#                            random_state=0, shuffle=False)\n",
    "# clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "# clf.fit(X, y)\n",
    "\n",
    "# so the X needs to be the observations of genes and the y needs to be the labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TASK 5 - talking about mean decrease gini vs gini score\n",
    " In scikit-learn, we implement the importance as described in [1] (often cited, but unfortunately rarely read…). It is sometimes called “gini importance” or “mean decrease impurity” and is defined as the total decrease in node impurity (weighted by the probability of reaching that node (which is approximated by the proportion of samples reaching that node)) averaged over all trees of the ensemble.\n",
    "from: https://medium.com/the-artificial-impostor/feature-importance-measures-for-tree-models-part-i-47f187c1a2c3\n",
    "I also remember Angela explaining me thay we want a high mean decrease in gini for a given gene because it basically represents how much worse the model would be at classifying in the absence of that given gene, or obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal: \n",
    "def randomForestClassifier (): #and feature selection? or separate? \n",
    "    clf = RandomForestClassifier(n_estimators=, random_state=0, n_jobs=-1, oob_score=True)\n",
    "    selector = RFECV(clf, step=0.2, cv=3, n_jobs=4) # step = % rounded down at each iteration  \n",
    "    \n",
    "    feat_labels = tiss.var_names \n",
    "    X = #adata X matrix (subsetted? what part?)\n",
    "    y = #labels\n",
    "    \n",
    "    print('training...')\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0) \n",
    "    clf.fit(X_train, y_train)\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_selected = feat_labels[selector.support_] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiss = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24m\n",
      "training...\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madelinepark/anaconda3/envs/scanpytest/lib/python3.6/site-packages/sklearn/ensemble/forest.py:460: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "/Users/madelinepark/anaconda3/envs/scanpytest/lib/python3.6/site-packages/sklearn/ensemble/forest.py:465: RuntimeWarning: invalid value encountered in true_divide\n",
      "  predictions[k].sum(axis=1)[:, np.newaxis])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8f3100847049>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mfeature_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeat_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scanpytest/lib/python3.6/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    519\u001b[0m         scores = parallel(\n\u001b[1;32m    520\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scanpytest/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scanpytest/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scanpytest/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scanpytest/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/scanpytest/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_age_cv = pd.DataFrame() #create results data frame \n",
    "\n",
    "for c in list(set(tiss.obs['age'])): \n",
    "    print(c)\n",
    "    age_of_interest = c\n",
    "    tiss.obs['age_type_of_interest'] = 'rest' #moved into, was outside before\n",
    "    tiss.obs.loc[tiss.obs['age'] == age_of_interest,'age_type_of_interest'] = age_of_interest\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=10, random_state=0, n_jobs=-1, oob_score=True)\n",
    "    selector = RFECV(clf, step=0.2, cv=3, n_jobs=4) # step = % rounded down at each iteration  \n",
    "    \n",
    "# #     tiss.obs.loc[tiss.obs[tiss.obs['age'] == age_of_interest].index,'age_type_of_interest'] = age_of_interest\n",
    "#     tiss.obs.loc[tiss.obs['age'] == age_of_interest,'age_type_of_interest'] = age_of_interest\n",
    "\n",
    "    feat_labels = tiss.var_names \n",
    "    X = tiss.X\n",
    "    y = tiss.obs['age_type_of_interest']\n",
    "    \n",
    "    print('training...')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0) \n",
    "    \n",
    "    \n",
    "    print(type(X_train))\n",
    "    print(type(y_train))\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    selector.fit(X_train, y_train)\n",
    "    feature_selected = feat_labels[selector.support_] \n",
    "    \n",
    "    print('result writing')\n",
    "    column_headings = []\n",
    "    column_headings.append(c)\n",
    "    column_headings.append(c + '_gini')\n",
    "    \n",
    "    resaux = pd.DataFrame(columns=column_headings)\n",
    "    resaux[c] = feature_selected\n",
    "    resaux[c + '_gini'] = (selector.estimator_.feature_importances_)\n",
    "    \n",
    "    print(feature_selected)\n",
    "    print (selector.estimator_.feature_importances_)\n",
    "    \n",
    "    results_age_cv = pd.concat([results_age_cv,resaux],axis=1)\n",
    "    \n",
    "    tiss.obs['age_type_of_interest'] = 'rest'\n",
    "    \n",
    "results_age_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goal: make a random forest where X is adata.X and y is the labels from labelsDict\n",
    "def makeOneClassForest(dataMatrix, classOfInterest, step=0.2, cv=3,  n_estimators=1000, random_state=0, n_jobs=-1, oob_score=True):\n",
    "    results_df = pd.DataFrame() \n",
    "    labelsDict = getLabels(dataMatrix = adata, classOfInterest = 'age') #is it bad to hardcode this\n",
    "    for label in list(labelsDict.keys()):\n",
    "        print(label)\n",
    "        \n",
    "        y = labelsDict[label] #list of strings \n",
    "        clf = RandomForestClassifier(n_estimators, random_state, n_jobs, oob_score)\n",
    "        selector = RFECV(clf, step, cv) # step = % rounded down at each iteration\n",
    "\n",
    "        clf.fit(dataMatrix.X, y) #confused if this y is labels or the genes because feat_labels is genes\n",
    "        selector.fit(dataMatrix.X, y)\n",
    "        feature_selected = dataMatrix.var_names[selector.support_] #check dataMatrix.var_names\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
