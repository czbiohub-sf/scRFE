{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import random\n",
    "import logging as logg\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all category columns in string columns\n",
    "def columnToString (dataMatrix):\n",
    "    cat_columns = dataMatrix.obs.select_dtypes(['category']).columns\n",
    "    dataMatrix.obs[cat_columns] = dataMatrix.obs[cat_columns].astype(str)\n",
    "    return dataMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove observations that are NaN for the category\n",
    "def filterNormalize (dataMatrix, classOfInterest, verbosity):\n",
    "    np.random.seed(644685)\n",
    "    dataMatrix = dataMatrix[dataMatrix.obs[classOfInterest]!='nan']\n",
    "    dataMatrix = dataMatrix[~dataMatrix.obs[classOfInterest].isna()]\n",
    "    if verbosity == True:\n",
    "        print ('Removed NaN observations in the selected category')\n",
    "    return dataMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the A/B labels for classification\n",
    "def labelSplit (dataMatrix, classOfInterest, labelOfInterest, verbosity):\n",
    "    dataMatrix = filterNormalize (dataMatrix, classOfInterest, verbosity)\n",
    "    dataMatrix.obs['classification_group'] = 'B'\n",
    "    dataMatrix.obs.loc[dataMatrix.obs[dataMatrix.obs[classOfInterest]==labelOfInterest]\n",
    "                   .index,'classification_group'] = 'A' #make labels based on A/B of classofInterest\n",
    "    return dataMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample observations to balance the groups\n",
    "def downsampleToSmallestCategory(dataMatrix, random_state, min_cells,\n",
    "                                 keep_small_categories, verbosity,\n",
    "                                 classOfInterest = 'classification_group',\n",
    ") -> sc.AnnData:\n",
    "    \"\"\"\n",
    "    returns an annData object in which all categories in 'classOfInterest' have\n",
    "    the same size\n",
    "    classOfInterest\n",
    "        column with the categories to downsample\n",
    "    min_cells\n",
    "        Minimum number of cells to downsample.\n",
    "        Categories having less than `min_cells` are discarded unless\n",
    "        keep_small_categories is True\n",
    "    keep_small_categories\n",
    "        Be default categories with less than min_cells are discarded.\n",
    "        Set to true to keep them\n",
    "    \"\"\"\n",
    "    counts = dataMatrix.obs[classOfInterest].value_counts(sort=False)\n",
    "    if len(counts[counts < min_cells]) > 0 and keep_small_categories is False:\n",
    "        logg.warning(\n",
    "            \"The following categories have less than {} cells and will be \"\n",
    "            \"ignored: {}\".format(min_cells, dict(counts[counts < min_cells]))\n",
    "        )\n",
    "    min_size = min(counts[counts >= min_cells])\n",
    "    sample_selection = None\n",
    "    for sample, num_cells in counts.items():\n",
    "        if num_cells <= min_cells:\n",
    "            if keep_small_categories:\n",
    "                sel = dataMatrix.obs.index.isin(\n",
    "                    dataMatrix.obs[dataMatrix.obs[classOfInterest] == sample].index)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            sel = dataMatrix.obs.index.isin(\n",
    "                dataMatrix.obs[dataMatrix.obs[classOfInterest] == sample]\n",
    "                .sample(min_size, random_state=random_state)\n",
    "                .index\n",
    "            )\n",
    "        if sample_selection is None:\n",
    "            sample_selection = sel\n",
    "        else:\n",
    "            sample_selection |= sel\n",
    "    logg.info(\n",
    "        \"The cells in category {!r} had been down-sampled to have each {} cells. \"\n",
    "        \"The original counts where {}\".format(classOfInterest, min_size, dict(counts))\n",
    "    )\n",
    "    return dataMatrix[sample_selection].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the random forest classifier and perform feature elimination\n",
    "def makeOneForest (dataMatrix, classOfInterest, labelOfInterest, nEstimators,\n",
    "                   randomState,  min_cells, keep_small_categories,\n",
    "                   nJobs, oobScore, Step, Cv, verbosity):\n",
    "    #need to add verbose arg details \n",
    "    \"\"\"\n",
    "    Builds and runs a random forest for one label in a class of interest\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataMatrix : anndata object\n",
    "        The data file of interest\n",
    "    classOfInterest : str\n",
    "        The class you will split the data by in the set of dataMatrix.obs\n",
    "    labelOfInterest : str\n",
    "        The specific label within the class that the random forezt will run a\n",
    "        \"one vs all\" classification on\n",
    "    nEstimators : int\n",
    "        The number of trees in the forest\n",
    "    randomState : int\n",
    "        Controls random number being used\n",
    "    nJobs : int\n",
    "        The number of jobs to run in parallel\n",
    "    oobScore : bool\n",
    "        Whether to use out-of-bag samples to estimate the generalization accuracy\n",
    "    Step : float\n",
    "        Corresponds to percentage of features to remove at each iteration\n",
    "    Cv : int\n",
    "        Determines the cross-validation splitting strategy\n",
    "    verbosity : bool \n",
    "        Whether to include print statements.\n",
    "    Returns\n",
    "    -------\n",
    "    feature_selected : list\n",
    "        list of top features from random forest\n",
    "    selector.estimator_.feature_importances_ : list\n",
    "        list of top ginis corresponding to to features\n",
    "    score : numpy.float\n",
    "    Score of underlying estimator.\n",
    "    X_new : sparse matrix \n",
    "    Transformed array of selected features.\n",
    "    y : pandas series\n",
    "    Target labels.\n",
    "    \"\"\"\n",
    "    splitDataMatrix = labelSplit (dataMatrix, classOfInterest, labelOfInterest, verbosity)\n",
    "\n",
    "    downsampledMatrix = downsampleToSmallestCategory (dataMatrix = splitDataMatrix, \n",
    "    random_state = randomState, min_cells = min_cells, \n",
    "        keep_small_categories = keep_small_categories, verbosity = verbosity,\n",
    "        classOfInterest = 'classification_group' )\n",
    "    \n",
    "    if verbosity == True:\n",
    "        print(labelOfInterest)\n",
    "        print(pd.DataFrame(downsampledMatrix.obs.groupby(['classification_group',classOfInterest])[classOfInterest].count()))\n",
    "\n",
    "    feat_labels = downsampledMatrix.var_names\n",
    "    X = downsampledMatrix.X\n",
    "    y = downsampledMatrix.obs['classification_group'] #'A' or 'B' labels from labelSplit\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators = nEstimators, random_state = randomState,\n",
    "                                 n_jobs = nJobs, oob_score = oobScore)\n",
    "\n",
    "    Cv = StratifiedKFold(Cv)\n",
    "    selector = RFECV(clf, step = Step, cv = Cv, scoring='f1_weighted', min_features_to_select=2)\n",
    "\n",
    "    clf.fit(X, y)\n",
    "    selector.fit(X, y)\n",
    "    feature_selected = feat_labels[selector.support_]\n",
    "    dataMatrix.obs['classification_group'] = 'B'\n",
    "    \n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    selector.fit(X_new, y) \n",
    "    score = selector.score(X_new, y)\n",
    "    feature_selected = feature_selected[selector.support_]\n",
    "\n",
    "    return feature_selected, selector.estimator_.feature_importances_,score,X_new,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the results\n",
    "def resultWrite (classOfInterest, results_df, labelOfInterest,\n",
    "                feature_selected, feature_importance):\n",
    "\n",
    "    column_headings = []\n",
    "    column_headings.append(labelOfInterest)\n",
    "    column_headings.append(labelOfInterest + '_gini')\n",
    "    resaux = pd.DataFrame(columns = column_headings)\n",
    "    resaux[labelOfInterest] = feature_selected\n",
    "    resaux[labelOfInterest + '_gini'] = feature_importance\n",
    "    resaux = resaux.sort_values(by = [labelOfInterest + '_gini'], ascending = False)\n",
    "    resaux.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    results_df = pd.concat([results_df, resaux], axis=1)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main scRFE function\n",
    "def scRFE (adata, classOfInterest, nEstimators = 1000, randomState = 0, min_cells = 15,\n",
    "        keep_small_categories = True, nJobs = -1, oobScore = True, Step = 0.2, Cv = 5, \n",
    "          verbosity = True):    \n",
    "    \"\"\"\n",
    "    Builds and runs a random forest with one vs all classification for each label\n",
    "    for one class of interest\n",
    "    Parameters\n",
    "    ----------\n",
    "    adata : anndata object\n",
    "        The data file of interest\n",
    "    classOfInterest : str\n",
    "        The class you will split the data by in the set of dataMatrix.obs\n",
    "    labelOfInterest : str\n",
    "        The specific label within the class that the random forezt will run a\n",
    "        \"one vs all\" classification on\n",
    "    nEstimators : int\n",
    "        The number of trees in the forest\n",
    "    randomState : int\n",
    "        Controls random number being used\n",
    "    min_cells : int\n",
    "        Minimum number of cells in a given class to downsample.\n",
    "    keep_small_categories : bool\n",
    "        Whether to keep classes with small number of observations, or to remove.\n",
    "    nJobs : int\n",
    "        The number of jobs to run in parallel\n",
    "    oobScore : bool\n",
    "        Whether to use out-of-bag samples to estimate the generalization accuracy\n",
    "    Step : float\n",
    "        Corresponds to percentage of features to remove at each iteration\n",
    "    Cv : int\n",
    "        Determines the cross-validation splitting strategy\n",
    "    verbosity : bool \n",
    "        Whether to include print statements.\n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pd.DataFrame\n",
    "        Dataframe with results for each label in the class, formatted as\n",
    "        \"label\" for one column, then \"label + gini\" for the corresponding column.\n",
    "    score_df: dict\n",
    "        Score for each label in classOfInterest.\n",
    "    \"\"\"\n",
    "    \n",
    "    dataMatrix = adata.copy()\n",
    "    dataMatrix = columnToString (dataMatrix)\n",
    "    dataMatrix = filterNormalize (dataMatrix, classOfInterest, verbosity)\n",
    "    results_df = pd.DataFrame()\n",
    "    \n",
    "    score_df = {}\n",
    "\n",
    "    for labelOfInterest in tqdm(np.unique(dataMatrix.obs[classOfInterest])):\n",
    "            \n",
    "        dataMatrix_labelOfInterest = dataMatrix.copy()\n",
    "\n",
    "        feature_selected, feature_importance, model_score, X_new, y =  makeOneForest(dataMatrix = dataMatrix, \n",
    "            classOfInterest = classOfInterest, labelOfInterest = labelOfInterest, \n",
    "            nEstimators = nEstimators, randomState = randomState,  min_cells = min_cells, \n",
    "                keep_small_categories = keep_small_categories,\n",
    "                   nJobs = nJobs, oobScore = oobScore, Step= Step, Cv=Cv, verbosity=verbosity)\n",
    "\n",
    "        results_df = resultWrite (classOfInterest, results_df,\n",
    "                            labelOfInterest = labelOfInterest,\n",
    "                    feature_selected = feature_selected,\n",
    "                    feature_importance = feature_importance)\n",
    "\n",
    "        score_df[labelOfInterest] = model_score\n",
    "\n",
    "    return results_df,score_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(scRFE1)",
   "language": "python",
   "name": "scrfe1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
