{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scRFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import random\n",
    "from anndata import read_h5ad\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scanpy.external as sce\n",
    "import logging as logg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnToString (dataMatrix):\n",
    "    cat_columns = dataMatrix.obs.select_dtypes(['category']).columns\n",
    "    dataMatrix.obs[cat_columns] = dataMatrix.obs[cat_columns].astype(str)\n",
    "    \n",
    "    return dataMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterNormalize (dataMatrix, classOfInterest):\n",
    "    np.random.seed(644685)\n",
    "#     sc.pp.filter_cells(dataMatrix, min_genes=0)\n",
    "#     sc.pp.filter_genes(dataMatrix, min_cells=0)\n",
    "    dataMatrix = dataMatrix[dataMatrix.obs[classOfInterest]!='nan']\n",
    "    dataMatrix = dataMatrix[~dataMatrix.obs[classOfInterest].isna()]\n",
    "    print ('na data removed')\n",
    "    return dataMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelSplit (dataMatrix, classOfInterest, labelOfInterest):\n",
    "    dataMatrix = filterNormalize (dataMatrix, classOfInterest)\n",
    "    dataMatrix.obs['classification_group'] = 'B'\n",
    "    dataMatrix.obs.loc[dataMatrix.obs[dataMatrix.obs[classOfInterest]==labelOfInterest]\n",
    "                   .index,'classification_group'] = 'A' #make labels based on A/B of\n",
    "#     classofInterest\n",
    "    return dataMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsampleToSmallestCategory(dataMatrix, random_state, min_cells, \n",
    "                                 keep_small_categories, \n",
    "                                 classOfInterest = 'classification_group',\n",
    ") -> sc.AnnData:\n",
    "    \"\"\"\n",
    "    returns an annData object in which all categories in 'classOfInterest' have\n",
    "    the same size\n",
    "    classOfInterest\n",
    "        column with the categories to downsample\n",
    "    min_cells\n",
    "        Minimum number of cells to downsample.\n",
    "        Categories having less than `min_cells` are discarded unless\n",
    "        keep_small_categories is True\n",
    "    keep_small_categories\n",
    "        Be default categories with less than min_cells are discarded.\n",
    "        Set to true to keep them\n",
    "    \"\"\"\n",
    "    counts = dataMatrix.obs[classOfInterest].value_counts(sort=False)\n",
    "    if len(counts[counts < min_cells]) > 0 and keep_small_categories is False:\n",
    "        logg.warning(\n",
    "            \"The following categories have less than {} cells and will be \"\n",
    "            \"ignored: {}\".format(min_cells, dict(counts[counts < min_cells]))\n",
    "        )\n",
    "    min_size = min(counts[counts >= min_cells])\n",
    "    sample_selection = None\n",
    "    for sample, num_cells in counts.items():\n",
    "        if num_cells <= min_cells:\n",
    "            if keep_small_categories:\n",
    "                sel = dataMatrix.obs.index.isin(\n",
    "                    dataMatrix.obs[dataMatrix.obs[classOfInterest] == sample].index)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            sel = dataMatrix.obs.index.isin(\n",
    "                dataMatrix.obs[dataMatrix.obs[classOfInterest] == sample]\n",
    "                .sample(min_size, random_state=random_state)\n",
    "                .index\n",
    "            )\n",
    "        if sample_selection is None:\n",
    "            sample_selection = sel\n",
    "        else:\n",
    "            sample_selection |= sel\n",
    "    logg.info(\n",
    "        \"The cells in category {!r} had been down-sampled to have each {} cells. \"\n",
    "        \"The original counts where {}\".format(classOfInterest, min_size, dict(counts))\n",
    "    )\n",
    "    return dataMatrix[sample_selection].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeOneForest (dataMatrix, classOfInterest, labelOfInterest, nEstimators, \n",
    "                   randomState,  min_cells, keep_small_categories,\n",
    "                   nJobs, oobScore, Step, Cv): \n",
    "\n",
    "    \"\"\"\n",
    "    Builds and runs a random forest for one label in a class of interest\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataMatrix : anndata object\n",
    "        The data file of interest\n",
    "    classOfInterest : str\n",
    "        The class you will split the data by in the set of dataMatrix.obs\n",
    "    labelOfInterest : str\n",
    "        The specific label within the class that the random forezt will run a \n",
    "        \"one vs all\" classification on\n",
    "    nEstimators : int\n",
    "        The number of trees in the forest\n",
    "    randomState : int\n",
    "        Controls random number being used\n",
    "    nJobs : int\n",
    "        The number of jobs to run in parallel\n",
    "    oobScore : bool\n",
    "        Whether to use out-of-bag samples to estimate the generalization accuracy\n",
    "    Step : float\n",
    "        Corresponds to percentage of features to remove at each iteration\n",
    "    Cv : int\n",
    "        Determines the cross-validation splitting strategy\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    feature_selected : list\n",
    "        list of top features from random forest\n",
    "    selector.estimator_.feature_importances_ : list\n",
    "        list of top ginis corresponding to to features\n",
    "    \n",
    "    \"\"\"\n",
    "    splitDataMatrix = labelSplit (dataMatrix, classOfInterest, labelOfInterest)\n",
    "    \n",
    "    downsampledMatrix = downsampleToSmallestCategory (dataMatrix = splitDataMatrix, \n",
    "    random_state = randomState, min_cells = min_cells, \n",
    "        keep_small_categories = keep_small_categories,\n",
    "        classOfInterest = 'classification_group', )\n",
    "\n",
    "    feat_labels = downsampledMatrix.var_names \n",
    "    X = downsampledMatrix.X\n",
    "    y = downsampledMatrix.obs['classification_group'] #'A' or 'B' labels from labelSplit\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators = nEstimators, random_state = randomState, \n",
    "                                 n_jobs = nJobs, oob_score = oobScore)\n",
    "    \n",
    "    selector = RFECV(clf, step = Step, cv = Cv)\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    selector.fit(X, y)\n",
    "    feature_selected = feat_labels[selector.support_] \n",
    "    dataMatrix.obs['classification_group'] = 'B'\n",
    "\n",
    "    return feature_selected, selector.estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultWrite (classOfInterest, results_df, labelOfInterest,\n",
    "                feature_selected, feature_importance):\n",
    "\n",
    "    column_headings = [] \n",
    "    column_headings.append(labelOfInterest)\n",
    "    column_headings.append(labelOfInterest + '_gini')\n",
    "    resaux = pd.DataFrame(columns = column_headings)\n",
    "    resaux[labelOfInterest] = feature_selected\n",
    "    resaux[labelOfInterest + '_gini'] = feature_importance\n",
    "    resaux = resaux.sort_values(by = [labelOfInterest + '_gini'], ascending = False)\n",
    "    resaux.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    results_df = pd.concat([results_df, resaux], axis=1)\n",
    "    return results_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scRFE (adata, classOfInterest, nEstimators = 5000, randomState = 0, min_cells = 15,\n",
    "        keep_small_categories = True, nJobs = -1, oobScore = True, Step = 0.2, Cv = 5):\n",
    "\n",
    "    \"\"\"\n",
    "    Builds and runs a random forest with one vs all classification for each label \n",
    "    for one class of interest\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataMatrix : anndata object\n",
    "        The data file of interest\n",
    "    classOfInterest : str\n",
    "        The class you will split the data by in the set of dataMatrix.obs\n",
    "    labelOfInterest : str\n",
    "        The specific label within the class that the random forezt will run a \n",
    "        \"one vs all\" classification on\n",
    "    nEstimators : int\n",
    "        The number of trees in the forest\n",
    "    randomState : int\n",
    "        Controls random number being used\n",
    "    min_cells : int\n",
    "        Minimum number of cells in a given class to downsample.\n",
    "    keep_small_categories : bool \n",
    "        Whether to keep classes with small number of observations, or to remove. \n",
    "    nJobs : int\n",
    "        The number of jobs to run in parallel\n",
    "    oobScore : bool\n",
    "        Whether to use out-of-bag samples to estimate the generalization accuracy\n",
    "    Step : float\n",
    "        Corresponds to percentage of features to remove at each iteration\n",
    "    Cv : int\n",
    "        Determines the cross-validation splitting strategy\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pd.DataFrame\n",
    "        Dataframe with results for each label in the class, formatted as \n",
    "        \"label\" for one column, then \"label + gini\" for the corresponding column\n",
    "    \n",
    "    \"\"\"\n",
    "    dataMatrix = adata.copy()\n",
    "    dataMatrix = columnToString (dataMatrix)\n",
    "    dataMatrix = filterNormalize (dataMatrix, classOfInterest)\n",
    "    results_df = pd.DataFrame()\n",
    "    \n",
    "    for labelOfInterest in sorted(np.unique(dataMatrix.obs[classOfInterest])): \n",
    "        dataMatrix_labelOfInterest = dataMatrix.copy()\n",
    "        \n",
    "        feature_selected, feature_importance =  makeOneForest(\n",
    "            dataMatrix = dataMatrix_labelOfInterest, classOfInterest = classOfInterest,\n",
    "            labelOfInterest = labelOfInterest,\n",
    "            nEstimators = nEstimators, randomState = randomState,  min_cells = min_cells, \n",
    "            keep_small_categories = keep_small_categories, nJobs = nJobs, \n",
    "            oobScore = oobScore, Step = Step, Cv = Cv)  \n",
    "    \n",
    "        results_df = resultWrite (classOfInterest, results_df, \n",
    "                            labelOfInterest = labelOfInterest, \n",
    "                    feature_selected = feature_selected,  \n",
    "                    feature_importance = feature_importance)\n",
    "        \n",
    "\n",
    "    return results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(scRFE1)",
   "language": "python",
   "name": "scrfe1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
